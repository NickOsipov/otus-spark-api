{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark - Работа с DataFrame\n",
    "\n",
    "## Введение в DataFrame\n",
    "DataFrame - это распределенная коллекция данных, организованная в именованные столбцы. Концептуально, он эквивалентен таблице в реляционной базе данных или DataFrame в R/Python, но с гораздо более богатыми возможностями оптимизации. В этом ноутбуке мы рассмотрим основные концепции и операции с DataFrame в PySpark.\n",
    "\n",
    "## Содержание\n",
    "1. Инициализация Spark и создание SparkSession\n",
    "2. Создание DataFrame\n",
    "3. Структура и схема DataFrame\n",
    "4. Основные операции с DataFrame\n",
    "5. Работа со столбцами\n",
    "6. Фильтрация и сортировка\n",
    "7. Агрегирование данных\n",
    "8. Операции над несколькими DataFrame\n",
    "9. Работа с типами данных\n",
    "10. Практические примеры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install findspark pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Инициализация Spark и создание SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт необходимых библиотек\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание SparkSession\n",
    "spark = (SparkSession\n",
    "    .builder\n",
    "    .appName(\"DataFrame Practice\")\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "# Проверка версии Spark\n",
    "print(f\"Spark Version: {spark.version}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Создание DataFrame\n",
    "Существует несколько способов создания DataFrame в PySpark.\n",
    "\n",
    "### Создание DataFrame из списка\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-------+------+---+\n",
      "|firstname|lastname|country| state|age|\n",
      "+---------+--------+-------+------+---+\n",
      "|    James|   Smith|    USA|    CA| 32|\n",
      "|  Michael|    Rose|    USA|    NY| 41|\n",
      "|   Robert|Williams|    USA|    CA| 42|\n",
      "|    Maria|   Jones|    USA|    FL| 38|\n",
      "|      Jen|   Brown|     UK|London| 29|\n",
      "+---------+--------+-------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Создание DataFrame из списка данных\n",
    "data = [(\"James\", \"Smith\", \"USA\", \"CA\", 32),\n",
    "        (\"Michael\", \"Rose\", \"USA\", \"NY\", 41),\n",
    "        (\"Robert\", \"Williams\", \"USA\", \"CA\", 42),\n",
    "        (\"Maria\", \"Jones\", \"USA\", \"FL\", 38),\n",
    "        (\"Jen\", \"Brown\", \"UK\", \"London\", 29)]\n",
    "\n",
    "# Определение схемы\n",
    "columns = [\"firstname\", \"lastname\", \"country\", \"state\", \"age\"]\n",
    "\n",
    "# Создание DataFrame\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Отображение DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание DataFrame из источников данных\n",
    "Сначала создадим несколько файлов с данными для примеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание CSV-файла\n",
    "csv_data = \"\"\"id,name,age,department,salary\n",
    "1,John,30,HR,55000\n",
    "2,Alice,25,IT,65000\n",
    "3,Bob,40,Finance,70000\n",
    "4,Carol,35,IT,68000\n",
    "5,David,45,Marketing,60000\n",
    "6,Eva,28,HR,50000\n",
    "7,Frank,50,Finance,75000\n",
    "8,Grace,33,Marketing,62000\n",
    "9,Henry,31,IT,69000\n",
    "10,Ivy,27,HR,53000\n",
    "\"\"\"\n",
    "\n",
    "with open(\"employees.csv\", \"w\") as f:\n",
    "    f.write(csv_data)\n",
    "\n",
    "# Создание JSON-файла\n",
    "json_data = \"\"\"\n",
    "{\"id\": 1, \"name\": \"Product A\", \"category\": \"Electronics\", \"price\": 1200.50, \"stock\": 100}\n",
    "{\"id\": 2, \"name\": \"Product B\", \"category\": \"Clothing\", \"price\": 25.99, \"stock\": 200}\n",
    "{\"id\": 3, \"name\": \"Product C\", \"category\": \"Electronics\", \"price\": 499.99, \"stock\": 50}\n",
    "{\"id\": 4, \"name\": \"Product D\", \"category\": \"Home & Kitchen\", \"price\": 99.95, \"stock\": 150}\n",
    "{\"id\": 5, \"name\": \"Product E\", \"category\": \"Clothing\", \"price\": 35.50, \"stock\": 300}\n",
    "\"\"\"\n",
    "\n",
    "with open(\"products.json\", \"w\") as f:\n",
    "    f.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для кластера\n",
    "!hadoop fs -put -f employees.csv /user/ubuntu/employees.csv\n",
    "!hadoop fs -put -f products.json /user/ubuntu/products.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтение из CSV-файла\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+----------+------+\n",
      "| id| name|age|department|salary|\n",
      "+---+-----+---+----------+------+\n",
      "|  1| John| 30|        HR| 55000|\n",
      "|  2|Alice| 25|        IT| 65000|\n",
      "|  3|  Bob| 40|   Finance| 70000|\n",
      "|  4|Carol| 35|        IT| 68000|\n",
      "|  5|David| 45| Marketing| 60000|\n",
      "|  6|  Eva| 28|        HR| 50000|\n",
      "|  7|Frank| 50|   Finance| 75000|\n",
      "|  8|Grace| 33| Marketing| 62000|\n",
      "|  9|Henry| 31|        IT| 69000|\n",
      "| 10|  Ivy| 27|        HR| 53000|\n",
      "+---+-----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Чтение DataFrame из CSV\n",
    "employees_df = spark.read.csv(\"employees.csv\", header=True, inferSchema=True)\n",
    "employees_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Информация о схеме\n",
    "employees_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтение из JSON-файла\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---+---------+------+-----+\n",
      "|      category| id|     name| price|stock|\n",
      "+--------------+---+---------+------+-----+\n",
      "|   Electronics|  1|Product A|1200.5|  100|\n",
      "|      Clothing|  2|Product B| 25.99|  200|\n",
      "|   Electronics|  3|Product C|499.99|   50|\n",
      "|Home & Kitchen|  4|Product D| 99.95|  150|\n",
      "|      Clothing|  5|Product E|  35.5|  300|\n",
      "+--------------+---+---------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Чтение DataFrame из JSON\n",
    "products_df = spark.read.json(\"products.json\")\n",
    "products_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- category: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- stock: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "products_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание DataFrame из Pandas DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание Pandas DataFrame\n",
    "pandas_df = pd.DataFrame({\n",
    "    'product_id': [1, 2, 3, 4, 5],\n",
    "    'product_name': ['Laptop', 'Phone', 'Tablet', 'Monitor', 'Keyboard'],\n",
    "    'price': [1200.0, 800.5, 350.75, 250.0, 50.0],\n",
    "    'in_stock': [True, True, False, True, False]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+------+--------+\n",
      "|product_id|product_name| price|in_stock|\n",
      "+----------+------------+------+--------+\n",
      "|         1|      Laptop|1200.0|    true|\n",
      "|         2|       Phone| 800.5|    true|\n",
      "|         3|      Tablet|350.75|   false|\n",
      "|         4|     Monitor| 250.0|    true|\n",
      "|         5|    Keyboard|  50.0|   false|\n",
      "+----------+------------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Преобразование в PySpark DataFrame\n",
    "spark_df = spark.createDataFrame(pandas_df)\n",
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- product_id: long (nullable = true)\n",
      " |-- product_name: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- in_stock: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Информация о схеме\n",
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Структура и схема DataFrame\n",
    "\n",
    "### Просмотр схемы DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Отображение схемы DataFrame\n",
    "employees_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType(List(StructField(id,IntegerType,true),StructField(name,StringType,true),StructField(age,IntegerType,true),StructField(department,StringType,true),StructField(salary,IntegerType,true)))\n"
     ]
    }
   ],
   "source": [
    "# Получение схемы в виде структуры\n",
    "schema = employees_df.schema\n",
    "print(schema)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Определение пользовательской схемы\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение пользовательской схемы\n",
    "custom_schema = StructType([\n",
    "    StructField(\"student_id\", StringType(), False),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"gpa\", DoubleType(), True),\n",
    "    StructField(\"active\", BooleanType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+---+---+------+\n",
      "|student_id|   name|age|gpa|active|\n",
      "+----------+-------+---+---+------+\n",
      "|      S001|  Alice| 20|3.8|  true|\n",
      "|      S002|    Bob| 22|3.5|  true|\n",
      "|      S003|Charlie| 21|3.9| false|\n",
      "|      S004|  Diana| 23|3.7|  true|\n",
      "+----------+-------+---+---+------+\n",
      "\n",
      "root\n",
      " |-- student_id: string (nullable = false)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- gpa: double (nullable = true)\n",
      " |-- active: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Данные\n",
    "data = [\n",
    "    (\"S001\", \"Alice\", 20, 3.8, True),\n",
    "    (\"S002\", \"Bob\", 22, 3.5, True),\n",
    "    (\"S003\", \"Charlie\", 21, 3.9, False),\n",
    "    (\"S004\", \"Diana\", 23, 3.7, True)\n",
    "]\n",
    "\n",
    "# Создание DataFrame с пользовательской схемой\n",
    "students_df = spark.createDataFrame(data, custom_schema)\n",
    "students_df.show()\n",
    "students_df.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Получение информации о столбцах\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['id', 'name', 'age', 'department', 'salary']\n"
     ]
    }
   ],
   "source": [
    "# Получение имен столбцов\n",
    "columns = employees_df.columns\n",
    "print(\"Columns:\", columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types: [('id', 'int'), ('name', 'string'), ('age', 'int'), ('department', 'string'), ('salary', 'int')]\n"
     ]
    }
   ],
   "source": [
    "# Получение типов данных столбцов\n",
    "dtypes = employees_df.dtypes\n",
    "print(\"Data Types:\", dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----+-----------------+----------+-----------------+\n",
      "|summary|                id| name|              age|department|           salary|\n",
      "+-------+------------------+-----+-----------------+----------+-----------------+\n",
      "|  count|                10|   10|               10|        10|               10|\n",
      "|   mean|               5.5| null|             34.4|      null|          62700.0|\n",
      "| stddev|3.0276503540974917| null|8.194849330863597|      null|8165.646194746487|\n",
      "|    min|                 1|Alice|               25|   Finance|            50000|\n",
      "|    max|                10| John|               50| Marketing|            75000|\n",
      "+-------+------------------+-----+-----------------+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Базовая статистика по числовым столбцам\n",
    "employees_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Основные операции с DataFrame\n",
    "\n",
    "### select() - выбор столбцов\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+------+\n",
      "| name|age|salary|\n",
      "+-----+---+------+\n",
      "| John| 30| 55000|\n",
      "|Alice| 25| 65000|\n",
      "|  Bob| 40| 70000|\n",
      "|Carol| 35| 68000|\n",
      "|David| 45| 60000|\n",
      "|  Eva| 28| 50000|\n",
      "|Frank| 50| 75000|\n",
      "|Grace| 33| 62000|\n",
      "|Henry| 31| 69000|\n",
      "|  Ivy| 27| 53000|\n",
      "+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Выбор отдельных столбцов\n",
    "employees_df.select(\"name\", \"age\", \"salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+------+-----------------+\n",
      "| name|age|salary|   monthly_salary|\n",
      "+-----+---+------+-----------------+\n",
      "| John| 30| 55000|4583.333333333333|\n",
      "|Alice| 25| 65000|5416.666666666667|\n",
      "|  Bob| 40| 70000|5833.333333333333|\n",
      "|Carol| 35| 68000|5666.666666666667|\n",
      "|David| 45| 60000|           5000.0|\n",
      "|  Eva| 28| 50000|4166.666666666667|\n",
      "|Frank| 50| 75000|           6250.0|\n",
      "|Grace| 33| 62000|5166.666666666667|\n",
      "|Henry| 31| 69000|           5750.0|\n",
      "|  Ivy| 27| 53000|4416.666666666667|\n",
      "+-----+---+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Выбор с использованием выражений\n",
    "employees_df.select(\n",
    "    col(\"name\"),\n",
    "    col(\"age\"),\n",
    "    col(\"salary\"),\n",
    "    (col(\"salary\") / 12).alias(\"monthly_salary\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### withColumn() - добавление/изменение столбца\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+----------+------+------+\n",
      "| id| name|age|department|salary| bonus|\n",
      "+---+-----+---+----------+------+------+\n",
      "|  1| John| 30|        HR| 55000|5500.0|\n",
      "|  2|Alice| 25|        IT| 65000|6500.0|\n",
      "|  3|  Bob| 40|   Finance| 70000|7000.0|\n",
      "|  4|Carol| 35|        IT| 68000|6800.0|\n",
      "|  5|David| 45| Marketing| 60000|6000.0|\n",
      "|  6|  Eva| 28|        HR| 50000|5000.0|\n",
      "|  7|Frank| 50|   Finance| 75000|7500.0|\n",
      "|  8|Grace| 33| Marketing| 62000|6200.0|\n",
      "|  9|Henry| 31|        IT| 69000|6900.0|\n",
      "| 10|  Ivy| 27|        HR| 53000|5300.0|\n",
      "+---+-----+---+----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Добавление нового столбца\n",
    "employees_with_bonus = employees_df.withColumn(\n",
    "    \"bonus\", col(\"salary\") * 0.1\n",
    ")\n",
    "employees_with_bonus.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+----------+------+\n",
      "| id| name|age|department|salary|\n",
      "+---+-----+---+----------+------+\n",
      "|  1| John| 30|        HR| 60000|\n",
      "|  2|Alice| 25|        IT| 70000|\n",
      "|  3|  Bob| 40|   Finance| 75000|\n",
      "|  4|Carol| 35|        IT| 73000|\n",
      "|  5|David| 45| Marketing| 65000|\n",
      "|  6|  Eva| 28|        HR| 55000|\n",
      "|  7|Frank| 50|   Finance| 80000|\n",
      "|  8|Grace| 33| Marketing| 67000|\n",
      "|  9|Henry| 31|        IT| 74000|\n",
      "| 10|  Ivy| 27|        HR| 58000|\n",
      "+---+-----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Изменение существующего столбца\n",
    "employees_modified = employees_df.withColumn(\n",
    "    \"salary\", col(\"salary\") + 5000\n",
    ")\n",
    "employees_modified.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### withColumnRenamed() - переименование столбца\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+---------+------+\n",
      "| id| name|age|     dept|salary|\n",
      "+---+-----+---+---------+------+\n",
      "|  1| John| 30|       HR| 55000|\n",
      "|  2|Alice| 25|       IT| 65000|\n",
      "|  3|  Bob| 40|  Finance| 70000|\n",
      "|  4|Carol| 35|       IT| 68000|\n",
      "|  5|David| 45|Marketing| 60000|\n",
      "|  6|  Eva| 28|       HR| 50000|\n",
      "|  7|Frank| 50|  Finance| 75000|\n",
      "|  8|Grace| 33|Marketing| 62000|\n",
      "|  9|Henry| 31|       IT| 69000|\n",
      "| 10|  Ivy| 27|       HR| 53000|\n",
      "+---+-----+---+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Переименование столбца\n",
    "employees_renamed = employees_df.withColumnRenamed(\"department\", \"dept\")\n",
    "employees_renamed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop() - удаление столбца\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+------+\n",
      "| id| name|age|salary|\n",
      "+---+-----+---+------+\n",
      "|  1| John| 30| 55000|\n",
      "|  2|Alice| 25| 65000|\n",
      "|  3|  Bob| 40| 70000|\n",
      "|  4|Carol| 35| 68000|\n",
      "|  5|David| 45| 60000|\n",
      "|  6|  Eva| 28| 50000|\n",
      "|  7|Frank| 50| 75000|\n",
      "|  8|Grace| 33| 62000|\n",
      "|  9|Henry| 31| 69000|\n",
      "| 10|  Ivy| 27| 53000|\n",
      "+---+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Удаление столбца\n",
    "employees_df.drop(\"department\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+\n",
      "| id| name|age|\n",
      "+---+-----+---+\n",
      "|  1| John| 30|\n",
      "|  2|Alice| 25|\n",
      "|  3|  Bob| 40|\n",
      "|  4|Carol| 35|\n",
      "|  5|David| 45|\n",
      "|  6|  Eva| 28|\n",
      "|  7|Frank| 50|\n",
      "|  8|Grace| 33|\n",
      "|  9|Henry| 31|\n",
      "| 10|  Ivy| 27|\n",
      "+---+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Удаление нескольких столбцов\n",
    "employees_df.drop(\"department\", \"salary\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Работа со столбцами\n",
    "\n",
    "### Функции для работы со строками\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+----------+-----------+-----------------+\n",
      "| name|upper_name|lower_name|name_length|        name_dept|\n",
      "+-----+----------+----------+-----------+-----------------+\n",
      "| John|      JOHN|      john|          4|        John - HR|\n",
      "|Alice|     ALICE|     alice|          5|       Alice - IT|\n",
      "|  Bob|       BOB|       bob|          3|    Bob - Finance|\n",
      "|Carol|     CAROL|     carol|          5|       Carol - IT|\n",
      "|David|     DAVID|     david|          5|David - Marketing|\n",
      "|  Eva|       EVA|       eva|          3|         Eva - HR|\n",
      "|Frank|     FRANK|     frank|          5|  Frank - Finance|\n",
      "|Grace|     GRACE|     grace|          5|Grace - Marketing|\n",
      "|Henry|     HENRY|     henry|          5|       Henry - IT|\n",
      "|  Ivy|       IVY|       ivy|          3|         Ivy - HR|\n",
      "+-----+----------+----------+-----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Работа со строковыми функциями\n",
    "df_string = employees_df.select(\n",
    "    col(\"name\"),\n",
    "    upper(col(\"name\")).alias(\"upper_name\"),\n",
    "    lower(col(\"name\")).alias(\"lower_name\"),\n",
    "    length(col(\"name\")).alias(\"name_length\"),\n",
    "    concat(col(\"name\"), lit(\" - \"), col(\"department\")).alias(\"name_dept\")\n",
    ")\n",
    "df_string.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+--------------+------------------+--------------------+\n",
      "| name|salary|rounded_salary|          sqrt_age|salary_diff_from_60k|\n",
      "+-----+------+--------------+------------------+--------------------+\n",
      "| John| 55000|         55000| 5.477225575051661|                5000|\n",
      "|Alice| 65000|         65000|               5.0|                5000|\n",
      "|  Bob| 70000|         70000| 6.324555320336759|               10000|\n",
      "|Carol| 68000|         68000| 5.916079783099616|                8000|\n",
      "|David| 60000|         60000| 6.708203932499369|                   0|\n",
      "|  Eva| 50000|         50000| 5.291502622129181|               10000|\n",
      "|Frank| 75000|         75000|7.0710678118654755|               15000|\n",
      "|Grace| 62000|         62000| 5.744562646538029|                2000|\n",
      "|Henry| 69000|         69000|5.5677643628300215|                9000|\n",
      "|  Ivy| 53000|         53000| 5.196152422706632|                7000|\n",
      "+-----+------+--------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Функции для работы с числами\n",
    "\n",
    "# Работа с числовыми функциями\n",
    "df_numeric = employees_df.select(\n",
    "    col(\"name\"),\n",
    "    col(\"salary\"),\n",
    "    round(col(\"salary\"), -3).alias(\"rounded_salary\"),\n",
    "    sqrt(col(\"age\")).alias(\"sqrt_age\"),\n",
    "    abs(col(\"salary\") - 60000).alias(\"salary_diff_from_60k\")\n",
    ")\n",
    "df_numeric.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функции для работы с датами\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание данных с датами\n",
    "date_data = [\n",
    "    (\"2023-01-15\", \"2023-01-15 10:30:00\"),\n",
    "    (\"2023-02-20\", \"2023-02-20 15:45:00\"),\n",
    "    (\"2023-03-25\", \"2023-03-25 08:15:00\"),\n",
    "    (\"2023-04-10\", \"2023-04-10 19:20:00\")\n",
    "]\n",
    "date_columns = [\"date_str\", \"timestamp_str\"]\n",
    "date_df = spark.createDataFrame(date_data, date_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-------------------+-------------------+\n",
      "|  date_str|      date|      timestamp_str|          timestamp|\n",
      "+----------+----------+-------------------+-------------------+\n",
      "|2023-01-15|2023-01-15|2023-01-15 10:30:00|2023-01-15 10:30:00|\n",
      "|2023-02-20|2023-02-20|2023-02-20 15:45:00|2023-02-20 15:45:00|\n",
      "|2023-03-25|2023-03-25|2023-03-25 08:15:00|2023-03-25 08:15:00|\n",
      "|2023-04-10|2023-04-10|2023-04-10 19:20:00|2023-04-10 19:20:00|\n",
      "+----------+----------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Преобразование строк в даты и временные метки\n",
    "date_df_converted = date_df.select(\n",
    "    col(\"date_str\"),\n",
    "    to_date(col(\"date_str\")).alias(\"date\"),\n",
    "    col(\"timestamp_str\"),\n",
    "    to_timestamp(col(\"timestamp_str\")).alias(\"timestamp\")\n",
    ")\n",
    "date_df_converted.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-----+---+-------------------+----+------+\n",
      "|      date|year|month|day|          timestamp|hour|minute|\n",
      "+----------+----+-----+---+-------------------+----+------+\n",
      "|2023-01-15|2023|    1| 15|2023-01-15 10:30:00|  10|    30|\n",
      "|2023-02-20|2023|    2| 20|2023-02-20 15:45:00|  15|    45|\n",
      "|2023-03-25|2023|    3| 25|2023-03-25 08:15:00|   8|    15|\n",
      "|2023-04-10|2023|    4| 10|2023-04-10 19:20:00|  19|    20|\n",
      "+----------+----+-----+---+-------------------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Извлечение частей даты\n",
    "date_parts_df = date_df_converted.select(\n",
    "    col(\"date\"),\n",
    "    year(col(\"date\")).alias(\"year\"),\n",
    "    month(col(\"date\")).alias(\"month\"),\n",
    "    dayofmonth(col(\"date\")).alias(\"day\"),\n",
    "    col(\"timestamp\"),\n",
    "    hour(col(\"timestamp\")).alias(\"hour\"),\n",
    "    minute(col(\"timestamp\")).alias(\"minute\")\n",
    ")\n",
    "date_parts_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+----------------+----------+\n",
      "|      date|date_plus_7days|date_minus_7days|days_since|\n",
      "+----------+---------------+----------------+----------+\n",
      "|2023-01-15|     2023-01-22|      2023-01-08|       877|\n",
      "|2023-02-20|     2023-02-27|      2023-02-13|       841|\n",
      "|2023-03-25|     2023-04-01|      2023-03-18|       808|\n",
      "|2023-04-10|     2023-04-17|      2023-04-03|       792|\n",
      "+----------+---------------+----------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Добавление/вычитание дней\n",
    "date_calc_df = date_df_converted.select(\n",
    "    col(\"date\"),\n",
    "    date_add(col(\"date\"), 7).alias(\"date_plus_7days\"),\n",
    "    date_sub(col(\"date\"), 7).alias(\"date_minus_7days\"),\n",
    "    datediff(current_date(), col(\"date\")).alias(\"days_since\")\n",
    ")\n",
    "date_calc_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Фильтрация и сортировка\n",
    "\n",
    "### filter() и where() - фильтрация строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+----------+------+\n",
      "| id| name|age|department|salary|\n",
      "+---+-----+---+----------+------+\n",
      "|  3|  Bob| 40|   Finance| 70000|\n",
      "|  5|David| 45| Marketing| 60000|\n",
      "|  7|Frank| 50|   Finance| 75000|\n",
      "+---+-----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Фильтрация с помощью filter\n",
    "employees_df.filter(col(\"age\") > 35).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+----------+------+\n",
      "| id| name|age|department|salary|\n",
      "+---+-----+---+----------+------+\n",
      "|  2|Alice| 25|        IT| 65000|\n",
      "|  4|Carol| 35|        IT| 68000|\n",
      "|  9|Henry| 31|        IT| 69000|\n",
      "+---+-----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Фильтрация с использованием where (эквивалентно filter)\n",
    "employees_df.where(col(\"department\") == \"IT\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+----------+------+\n",
      "| id| name|age|department|salary|\n",
      "+---+-----+---+----------+------+\n",
      "|  3|  Bob| 40|   Finance| 70000|\n",
      "|  4|Carol| 35|        IT| 68000|\n",
      "|  7|Frank| 50|   Finance| 75000|\n",
      "|  9|Henry| 31|        IT| 69000|\n",
      "+---+-----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Комбинированные условия\n",
    "employees_df.filter(\n",
    "    (col(\"age\") > 30) & (col(\"department\").isin(\"IT\", \"Finance\"))\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+----------+------+\n",
      "| id| name|age|department|salary|\n",
      "+---+-----+---+----------+------+\n",
      "|  2|Alice| 25|        IT| 65000|\n",
      "|  3|  Bob| 40|   Finance| 70000|\n",
      "|  4|Carol| 35|        IT| 68000|\n",
      "|  7|Frank| 50|   Finance| 75000|\n",
      "|  9|Henry| 31|        IT| 69000|\n",
      "+---+-----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Использование SQL-выражений\n",
    "employees_df.filter(\"salary >= 65000 AND department != 'Marketing'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### orderBy() и sort() - сортировка\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+----------+------+\n",
      "| id| name|age|department|salary|\n",
      "+---+-----+---+----------+------+\n",
      "|  6|  Eva| 28|        HR| 50000|\n",
      "| 10|  Ivy| 27|        HR| 53000|\n",
      "|  1| John| 30|        HR| 55000|\n",
      "|  5|David| 45| Marketing| 60000|\n",
      "|  8|Grace| 33| Marketing| 62000|\n",
      "|  2|Alice| 25|        IT| 65000|\n",
      "|  4|Carol| 35|        IT| 68000|\n",
      "|  9|Henry| 31|        IT| 69000|\n",
      "|  3|  Bob| 40|   Finance| 70000|\n",
      "|  7|Frank| 50|   Finance| 75000|\n",
      "+---+-----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Сортировка по одному столбцу\n",
    "employees_df.orderBy(\"salary\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+----------+------+\n",
      "| id| name|age|department|salary|\n",
      "+---+-----+---+----------+------+\n",
      "|  7|Frank| 50|   Finance| 75000|\n",
      "|  3|  Bob| 40|   Finance| 70000|\n",
      "|  1| John| 30|        HR| 55000|\n",
      "| 10|  Ivy| 27|        HR| 53000|\n",
      "|  6|  Eva| 28|        HR| 50000|\n",
      "|  9|Henry| 31|        IT| 69000|\n",
      "|  4|Carol| 35|        IT| 68000|\n",
      "|  2|Alice| 25|        IT| 65000|\n",
      "|  8|Grace| 33| Marketing| 62000|\n",
      "|  5|David| 45| Marketing| 60000|\n",
      "+---+-----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Сортировка по нескольким столбцам\n",
    "employees_df.orderBy(col(\"department\"), col(\"salary\").desc()).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+----------+------+\n",
      "| id| name|age|department|salary|\n",
      "+---+-----+---+----------+------+\n",
      "|  7|Frank| 50|   Finance| 75000|\n",
      "|  3|  Bob| 40|   Finance| 70000|\n",
      "|  1| John| 30|        HR| 55000|\n",
      "| 10|  Ivy| 27|        HR| 53000|\n",
      "|  6|  Eva| 28|        HR| 50000|\n",
      "|  9|Henry| 31|        IT| 69000|\n",
      "|  4|Carol| 35|        IT| 68000|\n",
      "|  2|Alice| 25|        IT| 65000|\n",
      "|  8|Grace| 33| Marketing| 62000|\n",
      "|  5|David| 45| Marketing| 60000|\n",
      "+---+-----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Эквивалентно с использованием sort()\n",
    "employees_df.sort(col(\"department\"), col(\"salary\").desc()).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Агрегирование данных\n",
    "\n",
    "### groupBy() - группировка данных\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|department|count|\n",
      "+----------+-----+\n",
      "|        HR|    3|\n",
      "|   Finance|    2|\n",
      "| Marketing|    2|\n",
      "|        IT|    3|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Группировка по отделу и подсчет сотрудников\n",
    "employees_df.groupBy(\"department\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+----------+----------+----------+------------+\n",
      "|department|employee_count|avg_salary|min_salary|max_salary|total_salary|\n",
      "+----------+--------------+----------+----------+----------+------------+\n",
      "|        HR|             3|  52666.67|     50000|     55000|      158000|\n",
      "|   Finance|             2|   72500.0|     70000|     75000|      145000|\n",
      "| Marketing|             2|   61000.0|     60000|     62000|      122000|\n",
      "|        IT|             3|  67333.33|     65000|     69000|      202000|\n",
      "+----------+--------------+----------+----------+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Группировка и вычисление нескольких метрик\n",
    "dept_metrics = employees_df.groupBy(\"department\").agg(\n",
    "    count(\"*\").alias(\"employee_count\"),\n",
    "    round(avg(\"salary\"), 2).alias(\"avg_salary\"),\n",
    "    min(\"salary\").alias(\"min_salary\"),\n",
    "    max(\"salary\").alias(\"max_salary\"),\n",
    "    sum(\"salary\").alias(\"total_salary\")\n",
    ")\n",
    "dept_metrics.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### agg() - агрегирование без группировки\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+----------+----------+------------+\n",
      "|employee_count|avg_salary|min_salary|max_salary|total_salary|\n",
      "+--------------+----------+----------+----------+------------+\n",
      "|            10|   62700.0|     50000|     75000|      627000|\n",
      "+--------------+----------+----------+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Агрегирование всего DataFrame\n",
    "employees_df.agg(\n",
    "    count(\"*\").alias(\"employee_count\"),\n",
    "    round(avg(\"salary\"), 2).alias(\"avg_salary\"),\n",
    "    min(\"salary\").alias(\"min_salary\"),\n",
    "    max(\"salary\").alias(\"max_salary\"),\n",
    "    sum(\"salary\").alias(\"total_salary\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оконные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+----------+------+----+----------+---------------------+\n",
      "| id| name|age|department|salary|rank|dense_rank|salary_diff_from_next|\n",
      "+---+-----+---+----------+------+----+----------+---------------------+\n",
      "|  1| John| 30|        HR| 55000|   1|         1|                 2000|\n",
      "| 10|  Ivy| 27|        HR| 53000|   2|         2|                 3000|\n",
      "|  6|  Eva| 28|        HR| 50000|   3|         3|                50000|\n",
      "|  7|Frank| 50|   Finance| 75000|   1|         1|                 5000|\n",
      "|  3|  Bob| 40|   Finance| 70000|   2|         2|                70000|\n",
      "|  8|Grace| 33| Marketing| 62000|   1|         1|                 2000|\n",
      "|  5|David| 45| Marketing| 60000|   2|         2|                60000|\n",
      "|  9|Henry| 31|        IT| 69000|   1|         1|                 1000|\n",
      "|  4|Carol| 35|        IT| 68000|   2|         2|                 3000|\n",
      "|  2|Alice| 25|        IT| 65000|   3|         3|                65000|\n",
      "+---+-----+---+----------+------+----+----------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Импорт оконных функций\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Создание оконной спецификации\n",
    "window_spec = Window.partitionBy(\"department\").orderBy(col(\"salary\").desc())\n",
    "\n",
    "# Применение оконных функций\n",
    "employees_with_rank = employees_df.withColumn(\n",
    "    \"rank\", rank().over(window_spec)\n",
    ").withColumn(\n",
    "    \"dense_rank\", dense_rank().over(window_spec)\n",
    ").withColumn(\n",
    "    \"salary_diff_from_next\", \n",
    "    col(\"salary\") - lead(\"salary\", 1, 0).over(window_spec)\n",
    ")\n",
    "\n",
    "employees_with_rank.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Операции над несколькими DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+----------+\n",
      "|  dept_id|           dept_name|  location|\n",
      "+---------+--------------------+----------+\n",
      "|       HR|     Human Resources|Building A|\n",
      "|       IT|Information Techn...|Building B|\n",
      "|  Finance|  Finance Department|Building A|\n",
      "|Marketing|Marketing Department|Building C|\n",
      "|    Sales|    Sales Department|Building C|\n",
      "+---------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Создание дополнительного DataFrame для демонстрации\n",
    "departments_data = [\n",
    "    (\"HR\", \"Human Resources\", \"Building A\"),\n",
    "    (\"IT\", \"Information Technology\", \"Building B\"),\n",
    "    (\"Finance\", \"Finance Department\", \"Building A\"),\n",
    "    (\"Marketing\", \"Marketing Department\", \"Building C\"),\n",
    "    (\"Sales\", \"Sales Department\", \"Building C\")\n",
    "]\n",
    "departments_columns = [\"dept_id\", \"dept_name\", \"location\"]\n",
    "departments_df = spark.createDataFrame(departments_data, departments_columns)\n",
    "departments_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `join()` - соединение DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+----------+------+---------+--------------------+----------+\n",
      "| id| name|age|department|salary|  dept_id|           dept_name|  location|\n",
      "+---+-----+---+----------+------+---------+--------------------+----------+\n",
      "| 10|  Ivy| 27|        HR| 53000|       HR|     Human Resources|Building A|\n",
      "|  6|  Eva| 28|        HR| 50000|       HR|     Human Resources|Building A|\n",
      "|  1| John| 30|        HR| 55000|       HR|     Human Resources|Building A|\n",
      "|  9|Henry| 31|        IT| 69000|       IT|Information Techn...|Building B|\n",
      "|  4|Carol| 35|        IT| 68000|       IT|Information Techn...|Building B|\n",
      "|  2|Alice| 25|        IT| 65000|       IT|Information Techn...|Building B|\n",
      "|  7|Frank| 50|   Finance| 75000|  Finance|  Finance Department|Building A|\n",
      "|  3|  Bob| 40|   Finance| 70000|  Finance|  Finance Department|Building A|\n",
      "|  8|Grace| 33| Marketing| 62000|Marketing|Marketing Department|Building C|\n",
      "|  5|David| 45| Marketing| 60000|Marketing|Marketing Department|Building C|\n",
      "+---+-----+---+----------+------+---------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Внутреннее соединение (inner join)\n",
    "inner_join_df = employees_df.join(\n",
    "    departments_df,\n",
    "    employees_df[\"department\"] == departments_df[\"dept_id\"],\n",
    "    \"inner\"\n",
    ")\n",
    "inner_join_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+----------+------+---------+--------------------+----------+\n",
      "| id| name|age|department|salary|  dept_id|           dept_name|  location|\n",
      "+---+-----+---+----------+------+---------+--------------------+----------+\n",
      "|  1| John| 30|        HR| 55000|       HR|     Human Resources|Building A|\n",
      "|  6|  Eva| 28|        HR| 50000|       HR|     Human Resources|Building A|\n",
      "| 10|  Ivy| 27|        HR| 53000|       HR|     Human Resources|Building A|\n",
      "|  3|  Bob| 40|   Finance| 70000|  Finance|  Finance Department|Building A|\n",
      "|  7|Frank| 50|   Finance| 75000|  Finance|  Finance Department|Building A|\n",
      "|  5|David| 45| Marketing| 60000|Marketing|Marketing Department|Building C|\n",
      "|  8|Grace| 33| Marketing| 62000|Marketing|Marketing Department|Building C|\n",
      "|  2|Alice| 25|        IT| 65000|       IT|Information Techn...|Building B|\n",
      "|  4|Carol| 35|        IT| 68000|       IT|Information Techn...|Building B|\n",
      "|  9|Henry| 31|        IT| 69000|       IT|Information Techn...|Building B|\n",
      "+---+-----+---+----------+------+---------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Левое внешнее соединение (left outer join)\n",
    "left_join_df = employees_df.join(\n",
    "    departments_df,\n",
    "    employees_df[\"department\"] == departments_df[\"dept_id\"],\n",
    "    \"left\"\n",
    ")\n",
    "left_join_df.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----+----------+------+---------+--------------------+----------+\n",
      "|  id| name| age|department|salary|  dept_id|           dept_name|  location|\n",
      "+----+-----+----+----------+------+---------+--------------------+----------+\n",
      "|  10|  Ivy|  27|        HR| 53000|       HR|     Human Resources|Building A|\n",
      "|   6|  Eva|  28|        HR| 50000|       HR|     Human Resources|Building A|\n",
      "|   1| John|  30|        HR| 55000|       HR|     Human Resources|Building A|\n",
      "|   9|Henry|  31|        IT| 69000|       IT|Information Techn...|Building B|\n",
      "|   4|Carol|  35|        IT| 68000|       IT|Information Techn...|Building B|\n",
      "|   2|Alice|  25|        IT| 65000|       IT|Information Techn...|Building B|\n",
      "|   7|Frank|  50|   Finance| 75000|  Finance|  Finance Department|Building A|\n",
      "|   3|  Bob|  40|   Finance| 70000|  Finance|  Finance Department|Building A|\n",
      "|   8|Grace|  33| Marketing| 62000|Marketing|Marketing Department|Building C|\n",
      "|   5|David|  45| Marketing| 60000|Marketing|Marketing Department|Building C|\n",
      "|null| null|null|      null|  null|    Sales|    Sales Department|Building C|\n",
      "+----+-----+----+----------+------+---------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Правое внешнее соединение (right outer join)\n",
    "right_join_df = employees_df.join(\n",
    "    departments_df,\n",
    "    employees_df[\"department\"] == departments_df[\"dept_id\"],\n",
    "    \"right\"\n",
    ")\n",
    "right_join_df.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----+----------+------+---------+--------------------+----------+\n",
      "|  id| name| age|department|salary|  dept_id|           dept_name|  location|\n",
      "+----+-----+----+----------+------+---------+--------------------+----------+\n",
      "|null| null|null|      null|  null|    Sales|    Sales Department|Building C|\n",
      "|   1| John|  30|        HR| 55000|       HR|     Human Resources|Building A|\n",
      "|   6|  Eva|  28|        HR| 50000|       HR|     Human Resources|Building A|\n",
      "|  10|  Ivy|  27|        HR| 53000|       HR|     Human Resources|Building A|\n",
      "|   3|  Bob|  40|   Finance| 70000|  Finance|  Finance Department|Building A|\n",
      "|   7|Frank|  50|   Finance| 75000|  Finance|  Finance Department|Building A|\n",
      "|   5|David|  45| Marketing| 60000|Marketing|Marketing Department|Building C|\n",
      "|   8|Grace|  33| Marketing| 62000|Marketing|Marketing Department|Building C|\n",
      "|   2|Alice|  25|        IT| 65000|       IT|Information Techn...|Building B|\n",
      "|   4|Carol|  35|        IT| 68000|       IT|Information Techn...|Building B|\n",
      "|   9|Henry|  31|        IT| 69000|       IT|Information Techn...|Building B|\n",
      "+----+-----+----+----------+------+---------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Полное внешнее соединение (full outer join)\n",
    "full_join_df = employees_df.join(\n",
    "    departments_df,\n",
    "    employees_df[\"department\"] == departments_df[\"dept_id\"],\n",
    "    \"full\"\n",
    ")\n",
    "full_join_df.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `union()` - объединение DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+----------+------+\n",
      "| id| name|age|department|salary|\n",
      "+---+-----+---+----------+------+\n",
      "| 11|Kevin| 29|     Sales| 58000|\n",
      "| 12|Laura| 32|        HR| 56000|\n",
      "+---+-----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Создание еще одного DataFrame для объединения\n",
    "more_employees_data = [\n",
    "    (11, \"Kevin\", 29, \"Sales\", 58000),\n",
    "    (12, \"Laura\", 32, \"HR\", 56000)\n",
    "]\n",
    "more_employees_df = spark.createDataFrame(more_employees_data, employees_df.columns)\n",
    "more_employees_df.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+----------+------+\n",
      "| id| name|age|department|salary|\n",
      "+---+-----+---+----------+------+\n",
      "|  1| John| 30|        HR| 55000|\n",
      "|  2|Alice| 25|        IT| 65000|\n",
      "|  3|  Bob| 40|   Finance| 70000|\n",
      "|  4|Carol| 35|        IT| 68000|\n",
      "|  5|David| 45| Marketing| 60000|\n",
      "|  6|  Eva| 28|        HR| 50000|\n",
      "|  7|Frank| 50|   Finance| 75000|\n",
      "|  8|Grace| 33| Marketing| 62000|\n",
      "|  9|Henry| 31|        IT| 69000|\n",
      "| 10|  Ivy| 27|        HR| 53000|\n",
      "| 11|Kevin| 29|     Sales| 58000|\n",
      "| 12|Laura| 32|        HR| 56000|\n",
      "+---+-----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Объединение DataFrame\n",
    "all_employees_df = employees_df.union(more_employees_df)\n",
    "all_employees_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Работа с типами данных\n",
    "\n",
    "### Приведение типов (cast)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------+-------------+\n",
      "|age|age_double|salary|salary_string|\n",
      "+---+----------+------+-------------+\n",
      "| 30|      30.0| 55000|        55000|\n",
      "| 25|      25.0| 65000|        65000|\n",
      "| 40|      40.0| 70000|        70000|\n",
      "| 35|      35.0| 68000|        68000|\n",
      "| 45|      45.0| 60000|        60000|\n",
      "| 28|      28.0| 50000|        50000|\n",
      "| 50|      50.0| 75000|        75000|\n",
      "| 33|      33.0| 62000|        62000|\n",
      "| 31|      31.0| 69000|        69000|\n",
      "| 27|      27.0| 53000|        53000|\n",
      "+---+----------+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Приведение типа столбца\n",
    "employees_df_with_cast = employees_df.withColumn(\n",
    "    \"age_double\", col(\"age\").cast(DoubleType())\n",
    ").withColumn(\n",
    "    \"salary_string\", col(\"salary\").cast(StringType())\n",
    ")\n",
    "employees_df_with_cast.select(\"age\", \"age_double\", \"salary\", \"salary_string\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Работа с NULL-значениями\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+------+\n",
      "| id| name|department|salary|\n",
      "+---+-----+----------+------+\n",
      "|  1| John|      null| 50000|\n",
      "|  2|Alice|        IT|  null|\n",
      "|  3| null|   Finance| 70000|\n",
      "|  4|David| Marketing| 60000|\n",
      "|  5|  Eva|      null|  null|\n",
      "+---+-----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Создание DataFrame с NULL-значениями\n",
    "null_data = [\n",
    "    (1, \"John\", None, 50000),\n",
    "    (2, \"Alice\", \"IT\", None),\n",
    "    (3, None, \"Finance\", 70000),\n",
    "    (4, \"David\", \"Marketing\", 60000),\n",
    "    (5, \"Eva\", None, None)\n",
    "]\n",
    "null_columns = [\"id\", \"name\", \"department\", \"salary\"]\n",
    "null_df = spark.createDataFrame(null_data, null_columns)\n",
    "null_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----------+------+\n",
      "| id|name|department|salary|\n",
      "+---+----+----------+------+\n",
      "|  1|John|      null| 50000|\n",
      "|  5| Eva|      null|  null|\n",
      "+---+----+----------+------+\n",
      "\n",
      "+---+-----+----------+------+\n",
      "| id| name|department|salary|\n",
      "+---+-----+----------+------+\n",
      "|  1| John|      null| 50000|\n",
      "|  3| null|   Finance| 70000|\n",
      "|  4|David| Marketing| 60000|\n",
      "+---+-----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Проверка на NULL\n",
    "null_df.filter(col(\"department\").isNull()).show()\n",
    "null_df.filter(col(\"salary\").isNotNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+------+\n",
      "| id| name|department|salary|\n",
      "+---+-----+----------+------+\n",
      "|  1| John|   Unknown| 50000|\n",
      "|  2|Alice|        IT|     0|\n",
      "|  3| null|   Finance| 70000|\n",
      "|  4|David| Marketing| 60000|\n",
      "|  5|  Eva|   Unknown|     0|\n",
      "+---+-----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Заполнение NULL-значений\n",
    "null_df.fillna({\"department\": \"Unknown\", \"salary\": 0}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Более сложная обработка NULL с when\n",
    "null_df.withColumn(\n",
    "    \"clean_department\",\n",
    "    when(col(\"department\").isNull(), \"Unknown\").otherwise(col(\"department\"))\n",
    ").withColumn(\n",
    "    \"clean_salary\",\n",
    "    when(col(\"salary\").isNull(), 0).otherwise(col(\"salary\"))\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаление строк с NULL-значениями\n",
    "null_df.na.drop().show()  # По умолчанию удаляет строки, где хотя бы в одном столбце есть NULL\n",
    "null_df.na.drop(\"all\").show()  # Удаляет строки, где во всех столбцах NULL\n",
    "null_df.na.drop(subset=[\"name\", \"department\"]).show()  # Удаляет строки с NULL в указанных столбцах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Практические примеры\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример 1: Анализ данных о сотрудниках\n",
    "\n",
    "# Для примера используем ранее созданный employees_df и departments_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Присоединяем данные об отделах\n",
    "employee_details = employees_df.join(\n",
    "    departments_df,\n",
    "    employees_df[\"department\"] == departments_df[\"dept_id\"],\n",
    "    \"left\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Создаем представление для использования SQL\n",
    "employee_details.createOrReplaceTempView(\"employee_details\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Анализ с помощью SQL\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        dept_name,\n",
    "        location,\n",
    "        COUNT(*) as employee_count,\n",
    "        ROUND(AVG(salary), 2) as avg_salary,\n",
    "        MIN(salary) as min_salary,\n",
    "        MAX(salary) as max_salary\n",
    "    FROM employee_details\n",
    "    GROUP BY dept_name, location\n",
    "    ORDER BY avg_salary DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Тот же анализ с использованием DataFrame API\n",
    "analysis_df = employee_details.groupBy(\"dept_name\", \"location\").agg(\n",
    "    count(\"*\").alias(\"employee_count\"),\n",
    "    round(avg(\"salary\"), 2).alias(\"avg_salary\"),\n",
    "    min(\"salary\").alias(\"min_salary\"),\n",
    "    max(\"salary\").alias(\"max_salary\")\n",
    ").orderBy(col(\"avg_salary\").desc())\n",
    "\n",
    "analysis_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Преобразование результатов в Pandas DataFrame для визуализации\n",
    "pandas_analysis = analysis_df.toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация средней зарплаты по отделам\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(pandas_analysis['dept_name'], pandas_analysis['avg_salary'])\n",
    "plt.title('Средняя зарплата по отделам')\n",
    "plt.xlabel('Отдел')\n",
    "plt.ylabel('Средняя зарплата')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример 2: Обработка данных о продажах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Создаем файл с данными о продажах\n",
    "sales_data = \"\"\"\n",
    "date,store_id,product_id,quantity,revenue\n",
    "2023-01-01,1,101,5,250.00\n",
    "2023-01-01,1,102,3,150.00\n",
    "2023-01-01,2,101,4,200.00\n",
    "2023-01-02,1,103,2,100.00\n",
    "2023-01-02,2,102,5,250.00\n",
    "2023-01-02,3,101,3,150.00\n",
    "2023-01-03,1,101,6,300.00\n",
    "2023-01-03,2,103,4,200.00\n",
    "2023-01-03,3,102,3,150.00\n",
    "2023-01-04,1,102,4,200.00\n",
    "2023-01-04,2,101,5,250.00\n",
    "2023-01-05,3,103,6,300.00\n",
    "\"\"\"\n",
    "\n",
    "with open(\"sales.csv\", \"w\") as f:\n",
    "    f.write(sales_data)\n",
    "\n",
    "# Создаем файл с информацией о магазинах\n",
    "stores_data = \"\"\"\n",
    "store_id,store_name,region\n",
    "1,Downtown Store,East\n",
    "2,Mall Store,West\n",
    "3,Suburban Store,North\n",
    "4,Online Store,Online\n",
    "\"\"\"\n",
    "\n",
    "with open(\"stores.csv\", \"w\") as f:\n",
    "    f.write(stores_data)\n",
    "\n",
    "# Создаем файл с информацией о продуктах\n",
    "products_data = \"\"\"\n",
    "product_id,product_name,category,unit_price\n",
    "101,Laptop,Electronics,500.00\n",
    "102,Smartphone,Electronics,400.00\n",
    "103,Headphones,Accessories,150.00\n",
    "104,Tablet,Electronics,300.00\n",
    "\"\"\"\n",
    "\n",
    "with open(\"products.csv\", \"w\") as f:\n",
    "    f.write(products_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -put -f sales.csv /user/ubuntu/sales.csv\n",
    "!hadoop fs -put -f stores.csv /user/ubuntu/stores.csv\n",
    "!hadoop fs -put -f products.csv /user/ubuntu/products.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтение данных в DataFrame\n",
    "sales_df = spark.read.csv(\"sales.csv\", header=True, inferSchema=True)\n",
    "stores_df = spark.read.csv(\"stores.csv\", header=True, inferSchema=True)\n",
    "products_df = spark.read.csv(\"products.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отображение загруженных данных\n",
    "print(\"Sales data:\")\n",
    "sales_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Stores data:\")\n",
    "stores_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Products data:\")\n",
    "products_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование строковой даты в тип date\n",
    "sales_df = sales_df.withColumn(\"date\", to_date(col(\"date\")))\n",
    "\n",
    "# Соединение данных о продажах с информацией о магазинах и продуктах\n",
    "sales_expanded_df = sales_df.join(\n",
    "    stores_df, on=\"store_id\", how=\"left\"\n",
    ").join(\n",
    "    products_df, on=\"product_id\", how=\"left\"\n",
    ")\n",
    "\n",
    "# Отображение объединенного DataFrame\n",
    "sales_expanded_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Анализ продаж по категориям продуктов и регионам\n",
    "category_region_sales = sales_expanded_df.groupBy(\"category\", \"region\").agg(\n",
    "    sum(\"quantity\").alias(\"total_quantity\"),\n",
    "    round(sum(\"revenue\"), 2).alias(\"total_revenue\"),\n",
    "    count(\"*\").alias(\"transaction_count\")\n",
    ").orderBy(\"category\", \"region\")\n",
    "\n",
    "category_region_sales.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Анализ продаж по дням\n",
    "daily_sales = sales_expanded_df.groupBy(\"date\").agg(\n",
    "    sum(\"quantity\").alias(\"total_quantity\"),\n",
    "    round(sum(\"revenue\"), 2).alias(\"total_revenue\"),\n",
    "    count(\"*\").alias(\"transaction_count\")\n",
    ").orderBy(\"date\")\n",
    "\n",
    "daily_sales.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование результатов в Pandas DataFrame для визуализации\n",
    "pandas_daily_sales = daily_sales.toPandas()\n",
    "pandas_category_sales = category_region_sales.toPandas()\n",
    "\n",
    "# Визуализация ежедневных продаж\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(pandas_daily_sales['date'], pandas_daily_sales['total_revenue'], marker='o')\n",
    "plt.title('Ежедневная выручка')\n",
    "plt.xlabel('Дата')\n",
    "plt.ylabel('Выручка')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация продаж по категориям и регионам\n",
    "pivot_sales = pandas_category_sales.pivot(index='category', columns='region', values='total_revenue')\n",
    "pivot_sales.fillna(0, inplace=True)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "pivot_sales.plot(kind='bar', stacked=True)\n",
    "plt.title('Продажи по категориям и регионам')\n",
    "plt.xlabel('Категория')\n",
    "plt.ylabel('Выручка')\n",
    "plt.legend(title='Регион')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Очистка после работы\n",
    "!rm employees.csv\n",
    "!rm products.json\n",
    "!rm sales.csv\n",
    "!rm stores.csv\n",
    "!rm products.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame практика завершена!\n"
     ]
    }
   ],
   "source": [
    "# Остановка SparkSession\n",
    "spark.stop()\n",
    "\n",
    "print(\"DataFrame практика завершена!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
